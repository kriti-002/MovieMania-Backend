{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9d57dce1-8bcf-49d0-a640-8f591ec42944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def retrieve_review():\n",
    "    # Example for MySQL\n",
    "    connection = pymysql.connect(\n",
    "        host='localhost',\n",
    "        user='root',\n",
    "        password='1234',\n",
    "        database='shoutreview',\n",
    "        autocommit=True\n",
    "    )\n",
    "    \n",
    "    cursor = connection.cursor()\n",
    "    # Query to extract reviews\n",
    "    query = \"select r.id, r.review from review r where r.sentiment is NULL\"\n",
    "    cursor.execute(query)\n",
    "    reviews = cursor.fetchall()\n",
    "    \n",
    "    # Convert the reviews from tuple format\n",
    "    reviews = [review for review in reviews]\n",
    "    \n",
    "    # Close connection\n",
    "    # connection.close()\n",
    "    return reviews\n",
    "retrieve_review()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a51e57d9-9709-469a-83b5-03b5e2e623af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Kriti\n",
      "[nltk_data]     Srivastava\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def preprocess_review(text):\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Tokenization\n",
    "    tokens = text.split()\n",
    "    # Remove stop words\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    # Join tokens back to string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def get_cleaned_reviews(reviews):\n",
    "    cleaned_reviews = [preprocess_review(review[1]) for review in reviews]\n",
    "    return reviews, cleaned_reviews\n",
    "get_cleaned_reviews(retrieve_review())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "24ba2eb5-2480-42c1-926d-2837970eb63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Kriti\n",
      "[nltk_data]     Srivastava\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "def get_sentiment(cleaned_reviews):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    # Analyze sentiment\n",
    "    sentiments = [sia.polarity_scores(review) for review in get_cleaned_reviews(retrieve_review())[1]]\n",
    "    \n",
    "    # Print first review and its sentiment\n",
    "    #print(sentiments[0])\n",
    "    reviews= [review[0] for review in get_cleaned_reviews(retrieve_review())[0]]\n",
    "    return sentiments, reviews\n",
    "get_sentiment(get_cleaned_reviews(retrieve_review())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "142e0ae1-c902-444b-b87e-2a30a4a76c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentiment(score):\n",
    "    if score > 0:\n",
    "        return 'positive'\n",
    "    elif score == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "827922c2-2be6-48e9-ae94-09350132bd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [07/Oct/2024 22:57:53] \"POST /analyze HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pymysql\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route('/analyze', methods=['POST'])\n",
    "def analyze_sentiment():  \n",
    "    try:\n",
    "        connection = pymysql.connect(\n",
    "        host='localhost',\n",
    "        user='root',\n",
    "        password='1234',\n",
    "        database='shoutreview',\n",
    "        autocommit=True)\n",
    "        cursor = connection.cursor()\n",
    "        \n",
    "        review= retrieve_review()\n",
    "        review= get_cleaned_reviews(review)\n",
    "        sentiments, review= get_sentiment(review)\n",
    "        sentiment_labels = [classify_sentiment(sentiment['compound']) for sentiment in sentiments]\n",
    "\n",
    "        for sentiment, review_id in zip(sentiment_labels, review):\n",
    "            insert_query = \"UPDATE review SET sentiment = %s WHERE id = %s\"\n",
    "            cursor.execute(insert_query, (sentiment, review_id))\n",
    "        connection.commit()\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "    finally:\n",
    "        connection.close()\n",
    "    \n",
    "    # Return the sentiment analysis result\n",
    "    return jsonify({\n",
    "        'message' : 'Done',\n",
    "        'sentiment' : sentiment_labels[0]\n",
    "    })\n",
    "\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59db9c4e-7224-4bb6-aad7-f4d7dc6b5208",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
